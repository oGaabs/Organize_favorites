import os
from dotenv import load_dotenv

import llm_agent

# Carregar variÃ¡veis de ambiente
load_dotenv()
CURRENT_DIR = os.getcwd()


def simple_folder_analysis():
  """Exemplo simples de anÃ¡lise de pasta com OpenRouter"""
  files = os.listdir(CURRENT_DIR)
  files_list = "\n".join([f"- {file}" for file in files])

  try:
    resposta = llm_agent.call_mistral_response(
        system_prompt=llm_agent.SYSTEM_ORGANIZER_PROMPT_V1,
        user_prompt=files_list,
        model=llm_agent.MODEL_MISTRAL,
        max_tokens=800,
    )
    print("ğŸ¤– SugestÃµes de OrganizaÃ§Ã£o:")
    print("=" * 40)
    print(resposta)
    print("=" * 40)
  except Exception as e:
    print(f"âŒ Erro: {str(e)}")


def chat_with_organizer():
  """Chat simples com o agente organizador"""
  print("ğŸ’¬ Chat com Agente Organizador")
  print("Digite 'sair' para terminar")
  print("-" * 30)
  while True:
    user_input = input("\nVocÃª: ")
    if user_input.lower() in ['sair', 'exit', 'quit']:
      print("ğŸ‘‹ AtÃ© logo!")
      break
    try:
      resposta = llm_agent.call_mistral_response_user(
          user_prompt=user_input,
          model="mistralai/mistral-small-3.2-24b-instruct:free",
          max_tokens=500,
      )
      print(f"\nğŸ¤– Agente: {resposta}")
    except Exception as e:
      print(f"âŒ Erro: {str(e)}")


if __name__ == "__main__":
  print("ğŸš€ Agente Organizador de Pastas - Exemplo Simples")
  print("\nEscolha uma opÃ§Ã£o:")
  print("1. Analisar pasta atual")
  print("2. Chat com agente")

  choice = input("\nOpÃ§Ã£o (1 ou 2): ").strip()

  if choice == "1":
    simple_folder_analysis()
  elif choice == "2":
    chat_with_organizer()
  else:
    print("âŒ OpÃ§Ã£o invÃ¡lida")
